Extracting ../MNIST_data/train-images-idx3-ubyte.gz
Extracting ../MNIST_data/train-labels-idx1-ubyte.gz
Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz
Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz
2017-06-13_00:04 start training
Batch 0: mean_loss 0.6876699924468994
2017-06-13_00:04 test results [0.68494922, 0.088399999]
Batch 100: mean_loss 0.4314008951187134
Batch 200: mean_loss 0.37692275643348694
Batch 300: mean_loss 0.3250066637992859
Batch 400: mean_loss 0.32334721088409424
Batch 500: mean_loss 0.3185063302516937
Batch 600: mean_loss 0.3126769959926605
Batch 700: mean_loss 0.3062303960323334
Batch 800: mean_loss 0.29618656635284424
Batch 900: mean_loss 0.2823489010334015
Batch 1000: mean_loss 0.267640084028244
2017-06-13_00:04 test results [0.2517193, 0.44469988]
Batch 1100: mean_loss 0.2532997727394104
Batch 1200: mean_loss 0.23802228271961212
Batch 1300: mean_loss 0.2232738435268402
Batch 1400: mean_loss 0.2084563970565796
Batch 1500: mean_loss 0.1955580860376358
Batch 1600: mean_loss 0.18560005724430084
Batch 1700: mean_loss 0.1753637194633484
Batch 1800: mean_loss 0.16538383066654205
Batch 1900: mean_loss 0.15681877732276917
Batch 2000: mean_loss 0.14779157936573029
2017-06-13_00:04 test results [0.14009622, 0.73559999]
Batch 2100: mean_loss 0.13731642067432404
Batch 2200: mean_loss 0.12848933041095734
Batch 2300: mean_loss 0.12075059115886688
Batch 2400: mean_loss 0.11323365569114685
Batch 2500: mean_loss 0.10721023380756378
Batch 2600: mean_loss 0.10220605880022049
Batch 2700: mean_loss 0.09787582606077194
Batch 2800: mean_loss 0.09309276938438416
Batch 2900: mean_loss 0.08850563317537308
Batch 3000: mean_loss 0.08593139797449112
2017-06-13_00:05 test results [0.083943769, 0.87540007]
Batch 3100: mean_loss 0.08204931020736694
Batch 3200: mean_loss 0.07828982174396515
Batch 3300: mean_loss 0.07521479576826096
Batch 3400: mean_loss 0.07107080519199371
Batch 3500: mean_loss 0.06516256183385849
Batch 3600: mean_loss 0.06012102589011192
Batch 3700: mean_loss 0.05619050934910774
Batch 3800: mean_loss 0.05202863737940788
Batch 3900: mean_loss 0.04838972166180611
Batch 4000: mean_loss 0.04590824246406555
2017-06-13_00:05 test results [0.043093733, 0.94790012]
Batch 4100: mean_loss 0.04563257098197937
Batch 4200: mean_loss 0.04386502876877785
Batch 4300: mean_loss 0.040469903498888016
Batch 4400: mean_loss 0.038258932530879974
Batch 4500: mean_loss 0.03797667846083641
Batch 4600: mean_loss 0.03674847632646561
Batch 4700: mean_loss 0.03508588671684265
Batch 4800: mean_loss 0.03450436890125275
Batch 4900: mean_loss 0.03393635153770447
Batch 5000: mean_loss 0.03262117877602577
2017-06-13_00:05 test results [0.031690191, 0.9568001]
Batch 5100: mean_loss 0.03151647001504898
Batch 5200: mean_loss 0.030290022492408752
Batch 5300: mean_loss 0.030366290360689163
Batch 5400: mean_loss 0.030356889590620995
Batch 5500: mean_loss 0.029097819700837135
Batch 5600: mean_loss 0.029370859265327454
Batch 5700: mean_loss 0.028243593871593475
Batch 5800: mean_loss 0.026869086548686028
Batch 5900: mean_loss 0.027646226808428764
Batch 6000: mean_loss 0.02719784528017044
2017-06-13_00:05 test results [0.026962578, 0.96300012]
Batch 6100: mean_loss 0.02609366364777088
Batch 6200: mean_loss 0.025802209973335266
Batch 6300: mean_loss 0.025796132162213326
Batch 6400: mean_loss 0.025599200278520584
Batch 6500: mean_loss 0.024115433916449547
Batch 6600: mean_loss 0.023169435560703278
Batch 6700: mean_loss 0.02469041757285595
Batch 6800: mean_loss 0.024519646540284157
Batch 6900: mean_loss 0.02304079756140709
Batch 7000: mean_loss 0.02215012162923813
2017-06-13_00:05 test results [0.02427797, 0.9653002]
Batch 7100: mean_loss 0.022238943725824356
Batch 7200: mean_loss 0.022668495774269104
Batch 7300: mean_loss 0.022802548483014107
Batch 7400: mean_loss 0.02275119349360466
Batch 7500: mean_loss 0.021387457847595215
Batch 7600: mean_loss 0.021402331069111824
Batch 7700: mean_loss 0.02168900892138481
Batch 7800: mean_loss 0.021272310987114906
Batch 7900: mean_loss 0.020919764414429665
Batch 8000: mean_loss 0.020851796492934227
2017-06-13_00:06 test results [0.022071762, 0.96820015]
Batch 8100: mean_loss 0.020247362554073334
Batch 8200: mean_loss 0.01933465525507927
Batch 8300: mean_loss 0.01905008591711521
Batch 8400: mean_loss 0.01969962567090988
Batch 8500: mean_loss 0.019772516563534737
Batch 8600: mean_loss 0.01950768753886223
Batch 8700: mean_loss 0.018895063549280167
Batch 8800: mean_loss 0.01866743713617325
Batch 8900: mean_loss 0.019184183329343796
Batch 9000: mean_loss 0.018806731328368187
2017-06-13_00:06 test results [0.022959065, 0.96410012]
Batch 9100: mean_loss 0.01874982751905918
Batch 9200: mean_loss 0.019123800098896027
Batch 9300: mean_loss 0.01859424263238907
Batch 9400: mean_loss 0.018100939691066742
Batch 9500: mean_loss 0.01835709623992443
Batch 9600: mean_loss 0.017241623252630234
Batch 9700: mean_loss 0.01687394268810749
Batch 9800: mean_loss 0.017825938761234283
Batch 9900: mean_loss 0.01858922466635704
Batch 10000: mean_loss 0.017679596319794655
2017-06-13_00:06 test results [0.020383853, 0.97120011]
Batch 10100: mean_loss 0.01767852157354355
Batch 10200: mean_loss 0.018328512087464333
Batch 10300: mean_loss 0.017119253054261208
Batch 10400: mean_loss 0.016483420506119728
Batch 10500: mean_loss 0.016712356358766556
Batch 10600: mean_loss 0.016486233100295067
Batch 10700: mean_loss 0.016651682555675507
Batch 10800: mean_loss 0.017478352412581444
Batch 10900: mean_loss 0.0168599970638752
Batch 11000: mean_loss 0.016036687418818474
2017-06-13_00:06 test results [0.021220364, 0.96810007]
Batch 11100: mean_loss 0.015748417004942894
Batch 11200: mean_loss 0.016291983425617218
Batch 11300: mean_loss 0.01612023636698723
Batch 11400: mean_loss 0.015460248105227947
Batch 11500: mean_loss 0.016380205750465393
Batch 11600: mean_loss 0.01621519774198532
Batch 11700: mean_loss 0.014959190972149372
Batch 11800: mean_loss 0.015127296559512615
Batch 11900: mean_loss 0.015116575174033642
Batch 12000: mean_loss 0.01495947502553463
2017-06-13_00:06 test results [0.020169565, 0.96970016]
Batch 12100: mean_loss 0.015271021984517574
Batch 12200: mean_loss 0.01499220635741949
Batch 12300: mean_loss 0.014328272081911564
Batch 12400: mean_loss 0.01514858566224575
Batch 12500: mean_loss 0.016533300280570984
Batch 12600: mean_loss 0.015208064578473568
Batch 12700: mean_loss 0.01385449431836605
Batch 12800: mean_loss 0.014131941832602024
Batch 12900: mean_loss 0.014454877004027367
Batch 13000: mean_loss 0.014192871749401093
2017-06-13_00:06 test results [0.018511381, 0.97350019]
Batch 13100: mean_loss 0.014260316267609596
Batch 13200: mean_loss 0.014738883823156357
Batch 13300: mean_loss 0.014553641900420189
Batch 13400: mean_loss 0.014068465679883957
Batch 13500: mean_loss 0.013524660840630531
Batch 13600: mean_loss 0.01363371592015028
Batch 13700: mean_loss 0.01345854066312313
Batch 13800: mean_loss 0.013414986431598663
Batch 13900: mean_loss 0.01357065699994564
Batch 14000: mean_loss 0.013551285490393639
2017-06-13_00:07 test results [0.016582115, 0.97460014]
Batch 14100: mean_loss 0.014042050577700138
Batch 14200: mean_loss 0.013539008796215057
Batch 14300: mean_loss 0.013237879611551762
Batch 14400: mean_loss 0.013629150576889515
Batch 14500: mean_loss 0.013838639482855797
Batch 14600: mean_loss 0.013390221633017063
Batch 14700: mean_loss 0.013083834201097488
Batch 14800: mean_loss 0.01333285216242075
Batch 14900: mean_loss 0.013269972987473011
Batch 15000: mean_loss 0.013349924236536026
2017-06-13_00:07 test results [0.016112648, 0.97540021]
Batch 15100: mean_loss 0.013047857210040092
Batch 15200: mean_loss 0.012413549236953259
Batch 15300: mean_loss 0.012501583434641361
Batch 15400: mean_loss 0.012659301981329918
Batch 15500: mean_loss 0.012294644489884377
Batch 15600: mean_loss 0.011766710318624973
Batch 15700: mean_loss 0.011389979161322117
Batch 15800: mean_loss 0.011603442020714283
Batch 15900: mean_loss 0.013085249811410904
Batch 16000: mean_loss 0.013336529955267906
2017-06-13_00:07 test results [0.016175417, 0.97710013]
Batch 16100: mean_loss 0.012160098180174828
Batch 16200: mean_loss 0.01223768200725317
Batch 16300: mean_loss 0.011875281110405922
Batch 16400: mean_loss 0.011150827631354332
Batch 16500: mean_loss 0.011185210198163986
Batch 16600: mean_loss 0.011781706474721432
Batch 16700: mean_loss 0.012279119342565536
Batch 16800: mean_loss 0.012167196720838547
Batch 16900: mean_loss 0.011467170901596546
Batch 17000: mean_loss 0.01096524577587843
2017-06-13_00:07 test results [0.016368955, 0.97540015]
Batch 17100: mean_loss 0.011844155378639698
Batch 17200: mean_loss 0.012428753077983856
Batch 17300: mean_loss 0.01218711119145155
Batch 17400: mean_loss 0.011151572689414024
Batch 17500: mean_loss 0.010137259028851986
Batch 17600: mean_loss 0.010948752984404564
Batch 17700: mean_loss 0.011269185692071915
Batch 17800: mean_loss 0.01103878952562809
Batch 17900: mean_loss 0.011450264602899551
Batch 18000: mean_loss 0.011555436067283154
2017-06-13_00:07 test results [0.015049255, 0.97860014]
Batch 18100: mean_loss 0.010935141704976559
Batch 18200: mean_loss 0.010866996832191944
Batch 18300: mean_loss 0.011287541128695011
Batch 18400: mean_loss 0.011147930286824703
Batch 18500: mean_loss 0.010728745721280575
Batch 18600: mean_loss 0.0111305620521307
Batch 18700: mean_loss 0.011296814307570457
Batch 18800: mean_loss 0.01069894153624773
Batch 18900: mean_loss 0.010847531259059906
Batch 19000: mean_loss 0.009990574792027473
2017-06-13_00:08 test results [0.016429456, 0.97650009]
Batch 19100: mean_loss 0.010091859847307205
Batch 19200: mean_loss 0.010941431857645512
Batch 19300: mean_loss 0.010913132689893246
Batch 19400: mean_loss 0.010824883356690407
Batch 19500: mean_loss 0.010174805298447609
Batch 19600: mean_loss 0.010177207179367542
Batch 19700: mean_loss 0.010412977077066898
Batch 19800: mean_loss 0.010503208264708519
Batch 19900: mean_loss 0.009969467297196388
Batch 20000: mean_loss 0.009716833010315895
2017-06-13_00:08 test results [0.014652386, 0.97750008]
Batch 20100: mean_loss 0.010161888785660267
Batch 20200: mean_loss 0.010421211831271648
Batch 20300: mean_loss 0.010114116594195366
Batch 20400: mean_loss 0.009774357080459595
Batch 20500: mean_loss 0.010095052421092987
Batch 20600: mean_loss 0.009754611179232597
Batch 20700: mean_loss 0.0100353192538023
Batch 20800: mean_loss 0.0101743433624506
Batch 20900: mean_loss 0.009447052143514156
Batch 21000: mean_loss 0.009848958812654018
2017-06-13_00:08 test results [0.015766045, 0.97750008]
Batch 21100: mean_loss 0.009839626960456371
Batch 21200: mean_loss 0.00995259266346693
Batch 21300: mean_loss 0.01018549408763647
Batch 21400: mean_loss 0.009486477822065353
Batch 21500: mean_loss 0.009906686842441559
Batch 21600: mean_loss 0.009958569891750813
Batch 21700: mean_loss 0.00922479759901762
Batch 21800: mean_loss 0.009560479782521725
Batch 21900: mean_loss 0.009339351207017899
Batch 22000: mean_loss 0.009315954521298409
2017-06-13_00:08 test results [0.014717589, 0.97900015]
Batch 22100: mean_loss 0.009606136940419674
Batch 22200: mean_loss 0.00906677171587944
Batch 22300: mean_loss 0.00898919627070427
Batch 22400: mean_loss 0.009036662988364697
Batch 22500: mean_loss 0.008568615652620792
Batch 22600: mean_loss 0.009634125977754593
Batch 22700: mean_loss 0.009993555024266243
Batch 22800: mean_loss 0.00939068105071783
Batch 22900: mean_loss 0.008978140540421009
Batch 23000: mean_loss 0.008336000144481659
2017-06-13_00:08 test results [0.015399156, 0.97780019]
Batch 23100: mean_loss 0.008964575827121735
Batch 23200: mean_loss 0.009856476448476315
Batch 23300: mean_loss 0.009114641696214676
Batch 23400: mean_loss 0.008416779339313507
Batch 23500: mean_loss 0.008879405446350574
Batch 23600: mean_loss 0.00868622213602066
Batch 23700: mean_loss 0.008803515695035458
Batch 23800: mean_loss 0.008380713872611523
Batch 23900: mean_loss 0.008323249407112598
Batch 24000: mean_loss 0.009264223277568817
2017-06-13_00:09 test results [0.015230341, 0.97740006]
Batch 24100: mean_loss 0.009269911795854568
Batch 24200: mean_loss 0.008581536822021008
Batch 24300: mean_loss 0.00784588698297739
Batch 24400: mean_loss 0.008470230735838413
Batch 24500: mean_loss 0.009485759772360325
Batch 24600: mean_loss 0.00883818045258522
Batch 24700: mean_loss 0.00850225705653429
Batch 24800: mean_loss 0.009006809443235397
Batch 24900: mean_loss 0.008837038651108742
Batch 25000: mean_loss 0.008512858301401138
2017-06-13_00:09 test results [0.01413408, 0.98080015]
2017-06-13_00:09 test results [0.014134079, 0.98080015]
